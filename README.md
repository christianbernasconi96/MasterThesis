# Overview
Deep Neural Networks (DNNs) in the field of Natural Language Processing (NLP) have proved to be of primary importance due to the significant benefit they can provide to a great diversity of applications. The NLP task of interest of this thesis is Entity Typing (ET), which aims to assign types from a type set to named entities appearing in a text, and it is beneficial for several NLP applications such as Question Answering, Entity Linking, Relation Extraction, and many others. When the type set has a high cardinality, this task takes the name of Fine-grained Entity Typing (FET). The type set of a FET dataset is usually organized in a hierarchical way, where the relations between coarse types and fine-grained types are represented by the edges of a tree. The main goal of this work is to study Neuro-Symbolic Integration (NSI) techniques to exploit hierarchical relations through the use of logical knowledge. Among the available NSI approaches, KENN is the framework chosen to conduct the experiments. KENN is a novel approach that seems suitable for our purpose since it allows injecting logical knowledge into a DNN in a very straightforward way. The focus of this thesis is to adapt KENN to the specifics of a FET problem by exploiting hierarchical information at its best. In particular, the experiments involve two popular FET datasets: BBN and FIGER.

See the [thesis](Thesis.pdf) and [presentation](Presentation.pdf) to learn more.

The code used to perform the experiments is available at [https://github.com/christianbernasconi96/MasterThesisExperiments](https://github.com/christianbernasconi96/MasterThesisExperiments)
