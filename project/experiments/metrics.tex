\subsection{Metrics for Entity Typing}
The evaluation of an ET approach relies on some variants of the metrics used in classical classification problems. The explanation of each metric will be supported by numerical values obtained from the example in Table~\ref{tab:metrics_example}. 

\begin{table}[H]
\centering
\caption{Example of predictions over a type set $T=\{T1, T2, T3\}$ and a dataset $X=\{X1, X2, X3\}$}
\label{tab:metrics_example}
\begin{tabular}{c|ccc|ccc|}
\cline{2-7}
                                       & \multicolumn{3}{c|}{\textbf{Prediction}}                                          & \multicolumn{3}{c|}{\textbf{Target}}                                              \\ \hline
\multicolumn{1}{|c|}{\textbf{Example}} & \multicolumn{1}{c|}{\textbf{T1}} & \multicolumn{1}{c|}{\textbf{T2}} & \textbf{T3} & \multicolumn{1}{c|}{\textbf{T1}} & \multicolumn{1}{c|}{\textbf{T2}} & \textbf{T3} \\ \hline
\multicolumn{1}{|c|}{X$_{1}$}          & x                                &                                  & x           & x                                & x                                &             \\ \hline
\multicolumn{1}{|c|}{X$_{2}$}          &                                  & x                                &             & x                                &                                  & x           \\ \hline
\multicolumn{1}{|c|}{X$_{3}$}          & x                                &                                  & x           & x                                &                                  & x           \\ \hline
\end{tabular}
\end{table}

In the definition of the metrics we will use terminology that needs a preliminary explanation:
\begin{itemize}
    \item True Positive (\textbf{TP}): number of correct positive predictions. In the example in Table~\ref{tab:metrics_example} we have TP=3 .
    \item False Positive (\textbf{FP}): number of wrong positive predictions. In the example in Table~\ref{tab:metrics_example} we have FP=2 .
    \item True Negative (\textbf{TN}): number of correct negative predictions. In the example in Table~\ref{tab:metrics_example} we have TN=1 .
    \item False Negative (\textbf{FN}): number of wrong negative predictions. In the example in Table~\ref{tab:metrics_example} we have FN=3 .
\end{itemize}

Once fixed these preliminary notions, the evaluated metrics are defined as follows:

\begin{itemize}
    \item \textbf{Accuracy:} percentage of correct predictions; defined as 
    \begin{gather*}
        \frac{count(Prediction == Target)}{|X|} = \frac{1}{3}
    \end{gather*}
    
    \item \textbf{Micro precision:} percentage of correct positive predictions with respect to all the positive predictions; defined as
    \begin{gather*}
        \frac{TP}{TP + FP} = \frac{3}{3 + 2} = 0.6
    \end{gather*}
    
    \item \textbf{Micro recall:} percentage of correct positive predictions with respect to the positive target; defined as
    \begin{gather*}
        \frac{TP}{TP + FN} = \frac{3}{3 + 3} = 0.5
    \end{gather*}
    
    \item \textbf{Micro f1:} harmonic mean of micro precision and micro recall; defined as
    \begin{gather*}
        2 \cdot \frac{MicroPrecision \cdot MicroRecall}{MicroPrecision + MicroRecall} =
        2 \cdot \frac{0.6 \cdot 0.5}{0.6 + 0.5} = 0.54
    \end{gather*}
    
    \item \textbf{Macro precision examples:} mean of the percentages of correct positive predictions with respect to all the positive predictions of each example; defined as
    \begin{gather*}
        \frac{\sum_{x \in X}\frac{TP(x)}{TP(x) + FP(x)}}{|X|}=
        \frac{0.5 + 0 + 1}{3}=0.5
    \end{gather*}
    
    \item \textbf{Macro recall examples:} mean of the percentages of correct positive predictions with respect to the positive target of each example; defined as
    \begin{gather*}
        \frac{\sum_{x \in X}\frac{TP(x)}{TP(x) + FN(x)}}{|X|}=
        \frac{0.5 + 0 + 1}{3}=0.5
    \end{gather*}
    
    \item \textbf{Macro f1 examples:} harmonic mean of micro precision examples and micro recall examples; defined as
    \begin{gather*}
        2 \cdot \frac{MacroPrecisionExamples \cdot MacroRecallExamples}{MacroPrecisionExamples + MacroRecallExamples} =\\
        = 2 \cdot \frac{0.5 \cdot 0.5}{0.5 + 0.5} = 0.5
    \end{gather*}
    
    \item \textbf{Macro precision classes:} mean of the percentages of correct positive predictions with respect to all the positive predictions of each class; defined as
    \begin{gather*}
        \frac{\sum_{t \in T}\frac{TP(t)}{TP(t) + FP(t)}}{|T|} =
        \frac{1 + 0 + 0.5}{3} = 0.5
    \end{gather*}
    
    \item \textbf{Macro recall classes:} mean of the percentages of correct positive predictions with respect to the positive target of each class; defined as
    \begin{gather*}
        \frac{\sum_{t \in T}\frac{TP(t)}{TP(t) + FN(t)}}{|T|} =
        \frac{0.66 + 0 + 0.5}{3} = 0.38
    \end{gather*}
    
    \item \textbf{Macro f1 classes:} harmonic mean of macro precision classes and macro recall classes; defined as
    \begin{gather*}
        2 \cdot \frac{MacroPrecisionClasses \cdot MacroRecallClasses}{MacroPrecisionClasses + MacroRecallClasses} = \\
        = 2 \cdot \frac{0.5 \cdot 0.38}{0.5 + 0.38} = 0.43
    \end{gather*}
\end{itemize}